{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/users/sista/jdan/neureka/neureka-codebase/vizualize-seizures\")\n",
    "EDF_ROOT = '/esat/biomeddata/Neureka_challenge/edf/dev/'\n",
    "\n",
    "import glob\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Dense, GRU, LSTM\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import resampy\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import nedc\n",
    "import spir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filenames():\n",
    "    filenames = list()\n",
    "    with h5py.File('evaluation/prediction_test_iclabel.h5', 'r') as f:\n",
    "        filenames = list(f['filenames'])\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def prepare_file(file_i, filename, classifiers, f_nick, model_type):    \n",
    "    # Load data\n",
    "    x = list()\n",
    "    for classifier in classifiers:\n",
    "        if classifier['format'] == 'nick':\n",
    "            z = list(f_nick[classifier['name']]['filenames'])\n",
    "            file_i =  z.index(filename)\n",
    "            predictions = f_nick[classifier['name']]['signals'][file_i]\n",
    "            predictions = downsample(predictions, 200, fs)\n",
    "        elif classifier['format'] == 'kaat':\n",
    "            predictions = loadmat(os.path.join(classifier['dir'], filename + classifier['file']))\n",
    "            predictions = predictions['score_predict'][0]\n",
    "            predictions = np.convolve(predictions, [0.5, 0.5], mode='valid')\n",
    "            if len(predictions) > len(x[0]):\n",
    "                predictions = predictions[:-(len(predictions)-len(x[0]))]\n",
    "            elif len(predictions) < len(x[0]):\n",
    "                predictions = np.concatenate((predictions, np.zeros(((len(x[0])-len(predictions))), )))\n",
    "        x.append(np.array(predictions, dtype=float))\n",
    "        \n",
    "    x = np.array(x)\n",
    "    x = np.transpose(x)\n",
    "    if model_type == 'lstm' or model_type == 'gru':\n",
    "        x = x.reshape((len(x), 1, len(x[0])))\n",
    "\n",
    "    \n",
    "    return x\n",
    "\n",
    "class AvgModel:\n",
    "    def fit(*argv, **kwargs):\n",
    "        return 0\n",
    "    \n",
    "    def reset_states(*argv, **kwargs):\n",
    "        return 0\n",
    "    \n",
    "    def predict(x, *argv, **kwargs):\n",
    "        if np.ndim(x) > 1:\n",
    "            return np.mean(x, axis=1)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "def downsample(x, oldFs, newFs):\n",
    "    return resampy.resample(x, oldFs, newFs)\n",
    "\n",
    "\n",
    "def findTse(filename):\n",
    "    result = glob.glob(os.path.join(EDF_ROOT, '*', filename[3:6], filename.split('_')[0], filename.split('_')[1] + '_' + '[0-9_]*', filename + '.tse'))\n",
    "    return result[0]\n",
    "\n",
    "\n",
    "def build_model(n_input, model_type, complexity=None):\n",
    "    if model_type == 'lstm':\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(complexity, stateful=True, return_sequences=False),\n",
    "                                input_shape=(1, n_input), batch_size=1))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "    elif model_type == 'gru':\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(GRU(complexity, stateful=True, return_sequences=False),\n",
    "                                input_shape=(1, n_input), batch_size=1))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "    elif model_type == 'dense':\n",
    "        model = Sequential()\n",
    "        model.add(Dense(1, activation='sigmoid', input_shape=(n_input, ), batch_size=1))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "    elif model_type == 'avg':\n",
    "        model = AvgModel\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, model_type, classifiers, filenames):\n",
    "    if model_type == 'avg':\n",
    "        return 0\n",
    "    \n",
    "    # Preload Nick data\n",
    "    f_nick = dict()\n",
    "    f_nick['ICA'] = h5py.File('evaluation/prediction_test_iclabel.h5', 'r')\n",
    "    f_nick['DNN'] = h5py.File('evaluation/prediction_test_raw.h5', 'r')\n",
    "    f_nick['DNN-wiener'] = h5py.File('evaluation/prediction_test_wiener.h5', 'r')\n",
    "    \n",
    "    # Train\n",
    "    for i, filename in enumerate(filenames):\n",
    "        x, y = prepare_file(i, filename, classifiers, f_nick, model_type)\n",
    "        if np.any(y):\n",
    "            model.fit(x, y, batch_size=1, epochs=15, verbose=1)\n",
    "        else:\n",
    "            model.fit(x, y, batch_size=1, epochs=1, verbose=1)\n",
    "        model.reset_states()\n",
    "        \n",
    "    # Close Nick data\n",
    "    for key in f_nick:\n",
    "        f_nick[key].close()\n",
    "\n",
    "        \n",
    "def test(model, modeltype, modelName, classifiers, filenames):\n",
    "    # Preload Nick data\n",
    "    f_nick = dict()\n",
    "    f_nick['ICA'] = h5py.File('evaluation/prediction_test_iclabel.h5', 'r')\n",
    "    f_nick['DNN'] = h5py.File('evaluation/prediction_test_raw.h5', 'r')\n",
    "    f_nick['DNN-wiener'] = h5py.File('evaluation/prediction_test_wiener.h5', 'r')\n",
    "    \n",
    "    # Predict probabilities\n",
    "    results = list()\n",
    "    for i, filename in enumerate(filenames):\n",
    "        x, y = prepare_file(i, filename, classifiers, f_nick, modeltype)\n",
    "        u = model.predict(x, batch_size=1)\n",
    "        model.reset_states()\n",
    "        results.append(u)\n",
    "        \n",
    "    # Build ROC curves\n",
    "    for threshold in np.arange(0.05, 1, step=0.05):\n",
    "        # Save results\n",
    "        resultDir = \"results/{}\".format(modelName)\n",
    "        resultFile = \"{}.txt\".format(str(threshold).split('.')[1][0:2])\n",
    "        pathlib.Path(resultDir).mkdir(parents=True, exist_ok=True)\n",
    "        with open(os.path.join(resultDir, resultFile), 'w') as handle:\n",
    "            for i, filename in enumerate(filenames):\n",
    "                events = spir.mask2eventList(results[i].flatten() > threshold, fs)\n",
    "                for event in events:\n",
    "                    handle.write('{} {} {} 1\\n'.format(filename, event[0], event[1]))\n",
    "                    \n",
    "    # Close Nick data\n",
    "    for key in f_nick:\n",
    "        f_nick[key].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1\n",
    "\n",
    "classifiers = [{\n",
    "    'name': 'ICA',\n",
    "    'file': 'evaluation/prediction_test_iclabel.h5',\n",
    "    'fs': 200,\n",
    "    'format': 'nick',    \n",
    "},\n",
    "    {\n",
    "    'name': 'DNN',\n",
    "    'file': 'evaluation/prediction_test_raw.h5',\n",
    "    'fs': 200,\n",
    "    'format': 'nick',    \n",
    "},\n",
    "{\n",
    "    'name': 'DNN-wiener',\n",
    "    'file': 'evaluation/prediction_test_wiener.h5',\n",
    "    'fs': 200,\n",
    "    'format': 'nick',\n",
    "}\n",
    "]\n",
    "\n",
    "modeltype = 'lstm'\n",
    "complexity = 4\n",
    "\n",
    "filenames = load_filenames()\n",
    "#model = build_model(len(classifiers), modeltype, complexity)\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('../vizualize-seizures/results/model-dnn-dnnw-dnnicalbl-lstm-4.h5')\n",
    "#train(model, modeltype, classifiers, filenames[0:100])\n",
    "#test(model, modeltype, 'all-{}-{}'.format(modeltype, complexity), classifiers, filenames[100:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_nick = dict()\n",
    "f_nick['ICA'] = h5py.File('evaluation/prediction_test_iclabel.h5', 'r')\n",
    "f_nick['DNN'] = h5py.File('evaluation/prediction_test_raw.h5', 'r')\n",
    "f_nick['DNN-wiener'] = h5py.File('evaluation/prediction_test_wiener.h5', 'r')\n",
    "\n",
    "# Predict probabilities\n",
    "results = list()\n",
    "for i, filename in enumerate(filenames):\n",
    "    x = prepare_file(i, filename, classifiers, f_nick, modeltype)\n",
    "    u = model.predict(x, batch_size=1)\n",
    "    model.reset_states()\n",
    "    results.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path('tmp').mkdir(parents=True, exist_ok=True)\n",
    "try:\n",
    "    os.remove(os.path.join('evaluation', 'hyp_lstm.txt'))\n",
    "except FileNotFoundError:\n",
    "    print('could not remove ref or hyp.txt')\n",
    "\n",
    "threshold = 0.55\n",
    "\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    \n",
    "    hyp = spir.mask2eventList((results[i].flatten() - np.median(results[i].flatten())) > threshold, fs)\n",
    "    #hyp = spir.mask2eventList(results[i] > threshold, fs)\n",
    "    hyp = spir.merge_events(hyp, 30)\n",
    "    \n",
    "    if len(hyp):\n",
    "        amp = list()\n",
    "        for event in hyp:\n",
    "            amp.append(np.mean(results[i].flatten()[int(event[0]*fs):int(event[1]*fs)]))\n",
    "        amp = np.array(amp)\n",
    "        amp /= np.max(amp)\n",
    "\n",
    "        hyp = list(np.array(hyp)[amp > 0.82])\n",
    "    \n",
    "    with open(os.path.join('evaluation', 'hyp_lstm.txt'), 'a') as handle:\n",
    "        for event in hyp:\n",
    "            if event[1] - event[0] > 15:\n",
    "                amp = np.sum(results[i][int(event[0]*fs):int(event[1]*fs)])\n",
    "                handle.write('{} {} {} 1.0 15\\n'.format(filename, event[0]+1, event[1]-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
